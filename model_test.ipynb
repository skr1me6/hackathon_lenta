{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNOBQCbYWDHs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ydata-profiling\n",
        "!pip install matplotlib\n",
        "!pip install seaborn\n",
        "!pip install tensorflow\n",
        "!pip install xgboost\n",
        "!pip install prophet\n",
        "!pip install catboost\n"
      ],
      "metadata": {
        "id": "qsGHxNrGWFY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# is Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from ydata_profiling import ProfileReport\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import xgboost as xgb\n",
        "import shutil\n",
        "from datetime import date, timedelta\n",
        "from datetime import datetime as dt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "import statsmodels.api as sm\n",
        "from prophet import Prophet\n",
        "import pickle\n",
        "from keras.models import load_model\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import os\n",
        "\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "id": "hT_MN-YJWFiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gAcRxmjKWFj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C1Q-UZtsWFly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gnDzqcxHWFnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Загрузка словаря из файла\n",
        "with open('historical_lags_season.pkl', 'rb') as f:\n",
        "    season_dfs = pickle.load(f)\n"
      ],
      "metadata": {
        "id": "53W13IVvWFpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "season_2 = season_dfs['lag_data_season_2']"
      ],
      "metadata": {
        "id": "UufI4DWwWNDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Загрузка словаря из файла\n",
        "with open('/kaggle/input/models-mapping/2_mapping.pkl', 'rb') as f:\n",
        "    mapping_2 = pickle.load(f)\n"
      ],
      "metadata": {
        "id": "4buFB35cWNBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st_id_encoder = {v: k for k, v in mapping_2['st_id_2_encoded'].items()}\n",
        "pr_sku_id_encoder = {v: k for k, v in mapping_2['pr_sku_id_2_encoded'].items()}\n"
      ],
      "metadata": {
        "id": "yPCz0DLJWM_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wape_loss(y_true, y_pred):\n",
        "    y_true_float = K.cast(y_true, dtype='float32')  # Преобразовать y_true в float32\n",
        "    error = K.abs(y_true_float - y_pred)\n",
        "    denominator = K.abs(y_true_float) + K.abs(y_pred)\n",
        "    return K.sum(error) / K.sum(denominator)"
      ],
      "metadata": {
        "id": "XN7n1MPlWQMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_objects = {'wape_loss': wape_loss}\n"
      ],
      "metadata": {
        "id": "CpQKzkGtWQKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = tf.keras.models.load_model('/kaggle/input/models-mapping/2.h5', custom_objects=custom_objects)\n"
      ],
      "metadata": {
        "id": "Yij1LD9KWQI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_end_date = season_2['date'].max()\n",
        "    # Вычисляем начальную дату, отсчитывая от конца\n",
        "test_start_date = test_end_date - timedelta(days=days_to_keep_in_test - 1)\n",
        "    # Фильтруем данные для тестовой выборки\n",
        "data_new_test = season_2[(season_2['date'] >= test_start_date) & (season_2['date'] <= test_end_date)]\n",
        "    # Фильтруем данные для тренировочной выборки (оставляем все, кроме тестовой части)\n",
        ""
      ],
      "metadata": {
        "id": "IMDl_MwrWQGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_new_test.drop(['date'],axis=1,inplace=True)\n",
        "features_lag_test = data_new_test.drop('pr_sales_in_units',axis=1)\n",
        "target_lag_test = data_new_test.pr_sales_in_units"
      ],
      "metadata": {
        "id": "YvyiJaChWQFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_lag_test['st_id_encoded'] = features_lag_test['st_id'].map(st_id_encoder)\n",
        "features_lag_test['pr_sku_id_encoded'] = features_lag_test['pr_sku_id'].map(pr_sku_id_encoder)"
      ],
      "metadata": {
        "id": "DjT2Vin6WM9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_lag_test['st_id_encoded'].fillna(value=999,inplace=True)\n",
        "features_lag_test['pr_sku_id_encoded'].fillna(value=9999,inplace=True)"
      ],
      "metadata": {
        "id": "LaamUaudWM7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_lag_test = features_lag_test.drop(['st_id','pr_sku_id'],axis=1)"
      ],
      "metadata": {
        "id": "kxTuIOp7WY_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_test_tensor = tf.convert_to_tensor(features_lag_test.values, dtype=tf.float32)\n",
        "target_test_tensor = tf.convert_to_tensor(target_lag_test.values, dtype=tf.int64)"
      ],
      "metadata": {
        "id": "YVvDm41VWY-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = model_2.evaluate(np.expand_dims(features_test_tensor, axis=-1), target_test_tensor)"
      ],
      "metadata": {
        "id": "cIauhbKFWY8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model_2.predict(features_test_tensor)\n"
      ],
      "metadata": {
        "id": "GyxH0trHWY6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cGMYRwW1WY4G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}