{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip intall numpy\n!pip intall pandas\n!pip intall matplotlib\n!pip intall seaborn\n!pip intall warnings\n!pip intall tqdm\n!pip intall ydata_profiling\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom ydata_profiling import ProfileReport\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\nimport warnings\nimport os\nfrom tqdm import tqdm\nfrom datetime import date, timedelta\nfrom datetime import datetime as dt\nimport os\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def wape(y_true: np.array, y_pred: np.array):\n    return np.sum(np.abs(y_true-y_pred))/np.sum(np.abs(y_true))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"current_directory = os.getcwd()\n\nfilename = \"pr_df.csv\"\n\nfile_path = os.path.join(current_directory, filename)\npr_df = pd.read_csv(file_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr_df.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr_df_hist_list = list(pr_df.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr_df_hist_list.pop(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename = \"sales_df_train.csv\"\n\nfile_path = os.path.join(current_directory, filename)\nsales_df_train = pd.read_csv('file_path')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def grab_float_columns(df):\n    return list(df.select_dtypes(include='float').columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"float_columns = grab_float_columns(sales_df_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"float_columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def check_nonzero_decimal(row):\n    decimal_part = row - int(row)\n    if decimal_part != 0:\n        raise StopIteration  # Выбрасываем исключение для завершения apply\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lst=[]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in float_columns:\n    try:\n        sales_df_train[i].apply(check_nonzero_decimal)\n        lst.append(i)\n    except StopIteration:\n        print(F'В колонке {i} есть как минимум одно число, у которого после запятой есть цифра отличная от нуля! ') ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Вывод:**\n\n* Можем для экономии памяти перевести из `float` типа в `int`","metadata":{}},{"cell_type":"code","source":"for i in float_columns:\n    sales_df_train[i] = sales_df_train[i].astype('int')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# столбец 'date' в формат datetime\nsales_df_train['date'] = pd.to_datetime(sales_df_train['date'])\n\n# столбец 'month' с номерами месяцев\nsales_df_train['month'] = sales_df_train['date'].dt.month\n\n# столбец 'day_of_week' с номерами дней недели (понедельник - 0, воскресенье - 6)\nsales_df_train['day_of_week'] = sales_df_train['date'].dt.dayofweek","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#  столбец 'season' с указанием времени года\nseasons = {\n    1: 'Зима',\n    2: 'Зима',\n    3: 'Весна',\n    4: 'Весна',\n    5: 'Весна',\n    6: 'Лето',\n    7: 'Лето',\n    8: 'Лето',\n    9: 'Осень',\n    10: 'Осень',\n    11: 'Осень',\n    12: 'Зима'\n}\nsales_df_train['season'] = sales_df_train['month'].map(seasons)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename = \"st_df.csv\"\n\nfile_path = os.path.join(current_directory, filename)\npr_st = pd.read_csv(filename)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr_st_active_only = pr_st.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr_st_active_only = pr_st_active_only[pr_st_active_only['st_is_active']==1].reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Объединение таблиц ","metadata":{}},{"cell_type":"code","source":"merged_df = sales_df_train.merge(pr_df, on='pr_sku_id', how='left')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_merged = merged_df.merge(pr_st_active_only, on='st_id', how='left')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_merged.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_merged.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"729 - это данные для неактивных магазинов. Можем удалять смело.","metadata":{}},{"cell_type":"code","source":"final_merged.dropna(inplace=True,ignore_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_merged.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_merged.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Добавление признаков","metadata":{}},{"cell_type":"code","source":"holiday_dict = {1:[i for i in range(1,10)],\n2:[23],\n3:[8],\n5:[1,9],\n6:[12],\n11:[4],\n12:[31]}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_flag_holiday(row, holiday_dict):\n    '''\n    Функция размечает даты - праздник / не праздник\n    :param row: Таблица\n    :param holiday_dct: Словарь месяц:[число(1),...,число(i)]\n    '''\n    \n    month = row['month']\n    day = row['date'].day\n    if month in holiday_dict and day in holiday_dict[month]:\n        return 1\n    return 0\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_merged['holiday'] = final_merged.apply(lambda row: set_flag_holiday(row, holiday_dict), axis=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_merged = final_merged.sort_values(by='date')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp_date = final_merged.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp_date['year'] = tmp_date['date'].dt.year\ntmp_date['day'] =tmp_date['date'].dt.day","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Предположим, что data_new - это ваш DataFrame\ntmp_date.rename(columns={'date': 'date_x'}, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создаем словарь для замены значений\nseason_mapping = {'Зима': 0, 'Весна': 1, 'Лето': 2, 'Осень': 3}\n\n# Заменяем значения в столбце 'season' согласно словарю\ntmp_date['season'] = tmp_date['season'].replace(season_mapping)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_group = tmp_date.groupby(['date_x', 'st_id', 'pr_sku_id']).agg({\n                                                                 'day':'mean' , \n                                                                 'day_of_week':'mean', \n                                                                    'month':'mean',\n                                                                    'year':'mean',\n                                                                    'season':'mean',\n                                                                 'holiday':'mean', \n                                                                 'pr_sales_in_units':'sum'\n                                                                })","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp=data_group.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp = tmp.reset_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_rec= tmp.drop_duplicates(subset=['date_x'])\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_rec.reset_index(drop=False,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def after_holidays_n_days(row, n_before):\n    if row['holiday'] == 1:\n        return 1\n    for i in range(1, n_before + 1):\n        if row.name - i < 0:\n            break\n        if unique_rec.at[row.name - i, 'holiday'] == 1:\n            return 1\n    return 0\n\ndef before_holidays_n_days(row, n_after):\n    if row['holiday'] == 1:\n        return 1\n    for i in range(1, n_after + 1):\n        if row.name + i >= len(unique_rec):\n            break\n        if unique_rec.at[row.name + i, 'holiday'] == 1:\n            return 1\n    return 0\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_before = 14  # Количество дней до и после праздника\nunique_rec['before_holidays_n_days'] = unique_rec.apply(lambda row: before_holidays_n_days(row, n_before), axis=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_after= 7\nunique_rec['after_holidays_n_days'] = unique_rec.apply(lambda row: after_holidays_n_days(row, n_after), axis=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"before_after_day = unique_rec.loc[:,['date_x','before_holidays_n_days','after_holidays_n_days']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp = tmp.merge(before_after_day, on='date_x', how='left')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp= tmp.drop(columns=['day','day_of_week','month','season'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Предположим, что data_new - это ваш DataFrame\ntmp.rename(columns={'date': 'date_x'}, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ntmp = tmp.reset_index().set_index('date_x')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp.drop('index',axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shop_list = tmp['st_id'].unique()\nproduct_list = tmp['pr_sku_id'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wape_results = {}\ntarget = 'pr_sales_in_units'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_new = pd.DataFrame()\nfor shop in shop_list:\n    data_chunk = tmp.query('st_id == \\'{0}\\''.format(shop))\n    for product in product_list:\n        data_chunk_2 = data_chunk.query('pr_sku_id == \\'{0}\\''.format(product))\n        if data_chunk_2.shape[0] != 0:\n            \n            #data_chunk_2 = data_chunk_2\n            data_chunk_2['month'] = data_chunk_2.index.month\n            data_chunk_2['year'] = data_chunk_2.index.year\n\n            idx = pd.date_range('{0}'.format(data_chunk_2.index.min()).replace('00:00:00', ''), '{0}'.format(data_chunk_2.index.max()).replace('00:00:00', ''))\n        \n            s = pd.Series({})\n\n            s.index = pd.DatetimeIndex(s.index)\n            s = s.reindex(idx, fill_value=0)\n            s = pd.DataFrame(s, index=s.index)\n\n            data_tmp = s.merge(data_chunk_2, left_index=True, right_on='date_x', how='left')\n            data_tmp['st_id'] = data_tmp['st_id'].fillna(shop) \n            data_tmp['pr_sku_id'] = data_tmp['pr_sku_id'].fillna(product) \n            data_tmp['target_rolling_mean_3'] = data_tmp['pr_sales_in_units'].shift().rolling(3).mean()\n           \n\n            data_new = pd.concat([data_new, data_tmp])\n\n\ndata_new","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_new.loc[data_new['pr_sales_in_units'].isna(), 'pr_sales_in_units'] = data_new[data_new['pr_sales_in_units'].isna()]['target_rolling_mean_3']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_new = data_new[~data_new['pr_sales_in_units'].isna()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_new.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_new.loc[data_new['pr_sales_in_units'].isna(), 'pr_sales_in_units'] = data_new[data_new['pr_sales_in_units'].isna()]['target_rolling_mean_3']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_new = data_new[~data_new['pr_sales_in_units'].isna()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_new = data_new.reset_index()\ndata_new['date'] = data_new['index']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_new.loc[data_new['date'].isna(), 'date'] = data_new[data_new['date'].isna()]['date_x']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_new = data_new.set_index('date')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_new = data_new.drop([0, 'index', 'date_x', 'target_rolling_mean_3'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_new.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_new= data_new.drop(columns=['month','year','holiday','before_holidays_n_days','after_holidays_n_days'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_new = data_new[data_new['pr_sales_in_units']>0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_new = data_new.reset_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_new['month'] = data_new.date.dt.month\ndata_new['day_of_week'] = data_new.date.dt.dayofweek\ndata_new['day'] = data_new.date.dt.day","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_new= data_new.drop(['month',\"day_of_week\",\"day\"],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_features(data,cos_sin_columns = ['month','day_of_week','day'],    holiday_dict = {1:[i for i in range(1,10)],\n    2:[23],\n    3:[8],\n    5:[1,9],\n    6:[12],\n    11:[4],\n    12:[31]}):\n    data['date'] = pd.to_datetime(data['date'])\n    data['month'] = data['date'].dt.month\n    \n    #  столбец 'season' с указанием времени года\n    seasons = {\n        1: 0,\n        2: 0,\n        3: 1,\n        4: 1,\n        5: 1,\n        6: 2,\n        7: 2,\n        8: 2,\n        9: 3,\n        10: 3,\n        11: 3,\n        12: 0\n    }\n    data['season'] = data['month'].map(seasons)\n    data['day'] = data['date'].dt.day\n    data['day_of_week'] =data['date'].dt.dayofweek\n    def set_flag_holiday(row, holiday_dict):\n        '''\n        Функция размечает даты - праздник / не праздник\n        :param row: Таблица\n        :param holiday_dct: Словарь месяц:[число(1),...,число(i)]\n        '''\n    \n        month = row['month']\n        day = row['date'].day\n        weekday = row['day_of_week']\n        if (month in holiday_dict and day in holiday_dict[month]):\n            return 1\n        return 0\n\n\n    data['holiday'] = data.apply(lambda row: set_flag_holiday(row, holiday_dict), axis=1)\n    def after_holidays_n_days(row, n_before=14):\n        if row['holiday'] == 1:\n            return 1\n        for i in range(1, n_before + 1):\n            if row.name - i < 0:\n                break\n            if unique_rec.at[row.name - i, 'holiday'] == 1:\n                return 1\n        return 0\n\n    def before_holidays_n_days(row, n_after=7):\n        if row['holiday'] == 1:\n            return 1\n        for i in range(1, n_after + 1):\n            if row.name + i >= len(unique_rec):\n                break\n            if unique_rec.at[row.name + i, 'holiday'] == 1:\n                return 1\n        return 0\n    \n    data = data.sort_values(by='date')\n    tmp=data.copy()\n    unique_rec= tmp.drop_duplicates(subset=['date'])\n    unique_rec.reset_index(drop=False,inplace=True)\n    unique_rec['before_holidays_n_days'] = unique_rec.apply(lambda row: before_holidays_n_days(row), axis=1)\n    unique_rec['after_holidays_n_days'] = unique_rec.apply(lambda row: after_holidays_n_days(row), axis=1)\n    before_after_day = unique_rec.loc[:,['date','before_holidays_n_days','after_holidays_n_days']]\n    data = data.merge(before_after_day, on='date', how='left')\n    \n    \n    def cos_sin_categorise(df,cos_column_name,sin_column_name,column_to_categorise):\n        \"\"\"\n        Применяет cos-sin тригонометрическую категоризацию\n\n        :param data: DataFrame содержащий данные\n        :param cos_column_name: Название будущей колонки с cos\n        :param sin_column_name: Название будущей колонки с sin\n        :param column_to_categorise: Назване колонки, которое хотим категоризовать\n        \"\"\"\n        df[cos_column_name] = np.cos((2*np.pi *df[column_to_categorise])/df[column_to_categorise].nunique())\n        df[sin_column_name] = np.sin((2*np.pi *df[column_to_categorise])/df[column_to_categorise].nunique())\n    \n    for i in cos_sin_columns:\n        cos_sin_categorise(data,f'cos_{i}',f'sin_{i}',i)\n\n    def set_flag_holiday_weekend(row, holiday_dict):\n        '''\n        Функция размечает даты - праздник / не праздник\n        :param row: Таблица\n        :param holiday_dct: Словарь месяц:[число(1),...,число(i)]\n        '''\n\n        month = row['month']\n        day = row['date'].day\n        weekday = row['day_of_week']\n        if (month in holiday_dict and day in holiday_dict[month])or (weekday in [5,6]):\n            return 1\n        return 0\n    data['holiday'] = data.apply(lambda row: set_flag_holiday_weekend(row, holiday_dict), axis=1)\n    data['date'] = pd.to_datetime(data['date'])\n    sales_df_train['date'] = pd.to_datetime(sales_df_train['date'])\n    data.drop(['day','month','day_of_week'],axis=1,inplace=True)\n    data = data.merge(pr_df, on='pr_sku_id', how='left')\n\n    data = data.merge(pr_st_active_only, on='st_id', how='left')\n    data = data.merge(sales_df_train.loc[:,['date','pr_sku_id','pr_sales_type_id']],on=['date','pr_sku_id'],how='left')\n    features_columns_list = ['st_id', 'pr_sku_id', 'date', 'holiday', 'season', 'cos_month', 'sin_month',\n       'cos_day_of_week', 'sin_day_of_week', 'cos_day', 'sin_day',\n       'before_holidays_n_days', 'after_holidays_n_days','pr_sales_type_id',\n       'pr_uom_id']\n    \n    data = data.reindex(columns=features_columns_list)\n\n    return data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_new = make_features(data_new)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"days_to_keep_in_test=14","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(42)\nfor season in tqdm(season_dataframes.keys(), desc=\"Processing Season\"):\n    test_end_date = season_dataframes[season]['date'].max()\n    # Вычисляем начальную дату, отсчитывая от конца\n    test_start_date = test_end_date - timedelta(days=days_to_keep_in_test - 1)\n    # Фильтруем данные для тестовой выборки\n    data_new_test = season_dataframes[season][(season_dataframes[season]['date'] >= test_start_date) & (season_dataframes[season]['date'] <= test_end_date)]\n    # Фильтруем данные для тренировочной выборки (оставляем все, кроме тестовой части)\n    data_new_train = season_dataframes[season][season_dataframes[season]['date'] < test_start_date]    \n    lag_df_train = pd.DataFrame()\n    # Перебираем уникальные пары магазин-товар\n    for store in tqdm(data_new_train.st_id.unique(), desc=\"Processing Stores Train\"):\n        for product in data_new_train.pr_sku_id.unique():\n            subset = data_new_train[(data_new_train['st_id'] == store) & (data_new_train['pr_sku_id'] == product)].copy()\n            # Фильтруем DataFrame для текущей пары магазин-товар\n            subset['lag_1_sales'] = subset['pr_sales_in_units'].shift(periods=1)\n            subset['lag_2_sales'] = subset['pr_sales_in_units'].shift(periods=2)\n            subset['lag_7_sales'] = subset['pr_sales_in_units'].shift(periods=7)\n            subset['lag_14_sales'] = subset['pr_sales_in_units'].shift(periods=14)\n            # Вычисляем скользящее среднее за 7 дней\n            subset['rolling_mean_2'] = subset['pr_sales_in_units'].shift().rolling(window=2).mean()\n            subset['rolling_mean_7'] = subset['pr_sales_in_units'].shift().rolling(window=7).mean()\n            subset['rolling_mean_14'] = subset['pr_sales_in_units'].shift().rolling(window=14).mean()\n\n\n            # Добавляем результаты в общий DataFrame\n            lag_df_train = pd.concat([lag_df_train, subset])\n            lag_df_train = lag_df_train.fillna(value=0)\n    # Создаем новый DataFrame для хранения лагов\n    lag_df_test = pd.DataFrame()\n\n    # Перебираем уникальные пары магазин-товар\n# Перебираем уникальные пары магазин-товар\n    for store in tqdm(data_new_test.st_id.unique(), desc=\"Processing Stores Test\"):\n        for product in data_new_test.pr_sku_id.unique():\n            # Фильтруем DataFrame для текущей пары магазин-товар\n            subset = data_new_test[(data_new_test['st_id'] == store) & (data_new_test['pr_sku_id'] == product)].copy()\n            # Создаем лаги\n            subset['lag_1_sales'] = subset['pr_sales_in_units'].shift(periods=1)\n            subset['lag_2_sales'] = subset['pr_sales_in_units'].shift(periods=2)\n            subset['lag_7_sales'] = subset['pr_sales_in_units'].shift(periods=7)\n            subset['lag_14_sales'] = subset['pr_sales_in_units'].shift(periods=14)\n            # Вычисляем скользящее среднее за 7 дней\n            subset['rolling_mean_2'] = subset['pr_sales_in_units'].shift().rolling(window=2, min_periods=2).mean()\n            subset['rolling_mean_7'] = subset['pr_sales_in_units'].shift().rolling(window=7, min_periods=7).mean()\n            subset['rolling_mean_14'] = subset['pr_sales_in_units'].shift().rolling(window=14, min_periods=14).mean()\n            # Заполняем пропущенные значения скользящим средним\n            # Добавляем результаты в общий DataFrame\n            lag_df_test = pd.concat([lag_df_test, subset])\n            lag_df_test = lag_df_test.fillna(value=0)\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_rolling_outliers(group):\n    group = group.sort_values(by='date')\n\n    group['rolling_mean'] = group['pr_sales_in_units'].expanding().mean()\n    group['rolling_std'] = group['pr_sales_in_units'].expanding().std()\n    group['zscore'] = (group['pr_sales_in_units'] - group['rolling_mean']) / group['rolling_std']\n\n    group['q1'] = group['pr_sales_in_units'].expanding().quantile(0.25)\n    group['q3'] = group['pr_sales_in_units'].expanding().quantile(0.75)\n    group['iqr'] = group['q3'] - group['q1']\n    group['lower_bound'] = group['q1'] - 1.5 * group['iqr']\n    group['upper_bound'] = group['q3'] + 1.5 * group['iqr']\n    group['is_outlier'] = ((group['zscore'].abs() > 3) |\n                           (group['pr_sales_in_units'] < group['lower_bound']) |\n                           (group['pr_sales_in_units'] > group['upper_bound'])).astype(int)\n\n    return group","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef detect_outliers(df_train, df_test):\n    df_train = df_train.groupby(['pr_sku_id', 'st_id'], group_keys=False).apply(calculate_rolling_outliers).reset_index(drop=True)\n\n    outlier_columns = ['q1', 'q3', 'iqr', 'lower_bound', 'upper_bound']\n    last_thresholds = df_train.groupby(['pr_sku_id', 'st_id'])[outlier_columns].last().reset_index()\n    df_test = pd.merge(df_test, last_thresholds, on=['pr_sku_id', 'st_id'], how='left')\n    df_test['is_outlier'] = ((df_test['pr_sales_in_units'] < df_test['lower_bound']) |\n                             (df_test['pr_sales_in_units'] > df_test['upper_bound'])).astype(int)\n    df_test.drop(outlier_columns, axis=1, inplace=True)\n\n    drop_cols_from_train = ['rolling_mean', 'rolling_std', 'zscore'] + outlier_columns\n    df_train.drop(drop_cols_from_train, axis=1, inplace=True)\n\n    return df_train, df_test","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lag_df_train,lag_df_test = detect_outliers(lag_df_train,lag_df_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lag_df_train.to_csv('train.csv')\nlag_df_test.to_csv('test.csv')","metadata":{},"execution_count":null,"outputs":[]}]}