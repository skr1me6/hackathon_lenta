{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import os\n",
        "from datetime import date, timedelta, datetime\n",
        "from tqdm import tqdm\n",
        "\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-10-09T08:06:39.948369Z",
          "iopub.execute_input": "2023-10-09T08:06:39.949212Z",
          "iopub.status.idle": "2023-10-09T08:06:39.966665Z",
          "shell.execute_reply.started": "2023-10-09T08:06:39.949159Z",
          "shell.execute_reply": "2023-10-09T08:06:39.965299Z"
        },
        "trusted": true,
        "id": "QlXnz7Hb-P8_",
        "outputId": "58cd9104-23dc-49f4-836f-08ee2431f438"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/whole-data-lags/whole_data_lags_test.csv\n/kaggle/input/whole-data-lags/whole_data_lags_train.csv\n/kaggle/input/result-for-preproccesing/pr_df.csv\n/kaggle/input/result-for-preproccesing/sales_df_train.csv\n/kaggle/input/result-for-preproccesing/sales_submission.csv\n/kaggle/input/result-for-preproccesing/st_df.csv\n/kaggle/input/catboost/catboost_model_41.8.pkl\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-09T08:06:42.245029Z",
          "iopub.execute_input": "2023-10-09T08:06:42.245645Z",
          "iopub.status.idle": "2023-10-09T08:06:42.265234Z",
          "shell.execute_reply.started": "2023-10-09T08:06:42.245612Z",
          "shell.execute_reply": "2023-10-09T08:06:42.263929Z"
        },
        "trusted": true,
        "id": "3vhb3mOa-P9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-09T08:06:43.266298Z",
          "iopub.execute_input": "2023-10-09T08:06:43.266643Z",
          "iopub.status.idle": "2023-10-09T08:06:43.271179Z",
          "shell.execute_reply.started": "2023-10-09T08:06:43.266618Z",
          "shell.execute_reply": "2023-10-09T08:06:43.270039Z"
        },
        "trusted": true,
        "id": "38t3DNBl-P9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wape(y_true: np.array, y_pred: np.array):\n",
        "    return np.sum(np.abs(y_true-y_pred))/np.sum(np.abs(y_true))\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "XXEryYsA-P9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "current_directory = os.getcwd()\n",
        "\n",
        "filename = \"pr_df.csv\"\n",
        "\n",
        "file_path = os.path.join(current_directory, filename)\n",
        "pr_df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-09T08:07:23.336016Z",
          "iopub.execute_input": "2023-10-09T08:07:23.336377Z",
          "iopub.status.idle": "2023-10-09T08:07:23.352266Z",
          "shell.execute_reply.started": "2023-10-09T08:07:23.336350Z",
          "shell.execute_reply": "2023-10-09T08:07:23.350978Z"
        },
        "trusted": true,
        "id": "Xur5LkhT-P9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pr_df.head(3)"
      ],
      "metadata": {
        "trusted": true,
        "id": "urljFCSG-P9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pr_df"
      ],
      "metadata": {
        "trusted": true,
        "id": "sm0jMVzW-P9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pr_df_hist_list = list(pr_df.columns)"
      ],
      "metadata": {
        "trusted": true,
        "id": "fLdbCIau-P9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pr_df_hist_list.pop(0)"
      ],
      "metadata": {
        "trusted": true,
        "id": "kaZ54O8u-P9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"sales_df_train.csv\"\n",
        "\n",
        "file_path = os.path.join(current_directory, filename)\n",
        "sales_df_train = pd.read_csv('file_path')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-09T08:07:24.816137Z",
          "iopub.execute_input": "2023-10-09T08:07:24.816554Z",
          "iopub.status.idle": "2023-10-09T08:07:26.674689Z",
          "shell.execute_reply.started": "2023-10-09T08:07:24.816524Z",
          "shell.execute_reply": "2023-10-09T08:07:26.673745Z"
        },
        "trusted": true,
        "id": "HrNhrDyX-P9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grab_float_columns(df):\n",
        "    return list(df.select_dtypes(include='float').columns)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ecrePUUw-P9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "float_columns = grab_float_columns(sales_df_train)"
      ],
      "metadata": {
        "trusted": true,
        "id": "2dYHjEFe-P9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "float_columns"
      ],
      "metadata": {
        "trusted": true,
        "id": "XguQhyHl-P9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_nonzero_decimal(row):\n",
        "    decimal_part = row - int(row)\n",
        "    if decimal_part != 0:\n",
        "        raise StopIteration  # Выбрасываем исключение для завершения apply\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "xb7ZQPUz-P9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst=[]"
      ],
      "metadata": {
        "trusted": true,
        "id": "V_J5H5P_-P9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in float_columns:\n",
        "    try:\n",
        "        sales_df_train[i].apply(check_nonzero_decimal)\n",
        "        lst.append(i)\n",
        "    except StopIteration:\n",
        "        print(F'В колонке {i} есть как минимум одно число, у которого после запятой есть цифра отличная от нуля! ')"
      ],
      "metadata": {
        "trusted": true,
        "id": "7jNTLJA0-P9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4rYYXvEz-P9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод:**\n",
        "\n",
        "* Можем для экономии памяти перевести из `float` типа в `int`"
      ],
      "metadata": {
        "id": "K3MZl7hB-P9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in float_columns:\n",
        "    sales_df_train[i] = sales_df_train[i].astype('int')"
      ],
      "metadata": {
        "trusted": true,
        "id": "6qr-ZEd6-P9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# столбец 'date' в формат datetime\n",
        "sales_df_train['date'] = pd.to_datetime(sales_df_train['date'])\n",
        "\n",
        "# столбец 'month' с номерами месяцев\n",
        "sales_df_train['month'] = sales_df_train['date'].dt.month\n",
        "\n",
        "# столбец 'day_of_week' с номерами дней недели (понедельник - 0, воскресенье - 6)\n",
        "sales_df_train['day_of_week'] = sales_df_train['date'].dt.dayofweek"
      ],
      "metadata": {
        "trusted": true,
        "id": "weMktGa3-P9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  столбец 'season' с указанием времени года\n",
        "seasons = {\n",
        "    1: 'Зима',\n",
        "    2: 'Зима',\n",
        "    3: 'Весна',\n",
        "    4: 'Весна',\n",
        "    5: 'Весна',\n",
        "    6: 'Лето',\n",
        "    7: 'Лето',\n",
        "    8: 'Лето',\n",
        "    9: 'Осень',\n",
        "    10: 'Осень',\n",
        "    11: 'Осень',\n",
        "    12: 'Зима'\n",
        "}\n",
        "sales_df_train['season'] = sales_df_train['month'].map(seasons)"
      ],
      "metadata": {
        "trusted": true,
        "id": "3DCl_D7E-P9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"st_df.csv\"\n",
        "\n",
        "file_path = os.path.join(current_directory, filename)\n",
        "pr_st = pd.read_csv(filename)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-09T08:07:32.303331Z",
          "iopub.execute_input": "2023-10-09T08:07:32.303678Z",
          "iopub.status.idle": "2023-10-09T08:07:32.321407Z",
          "shell.execute_reply.started": "2023-10-09T08:07:32.303652Z",
          "shell.execute_reply": "2023-10-09T08:07:32.320039Z"
        },
        "trusted": true,
        "id": "jF80YWSI-P9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pr_st_active_only = pr_st.copy()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-09T08:07:32.530156Z",
          "iopub.execute_input": "2023-10-09T08:07:32.530638Z",
          "iopub.status.idle": "2023-10-09T08:07:32.536031Z",
          "shell.execute_reply.started": "2023-10-09T08:07:32.530598Z",
          "shell.execute_reply": "2023-10-09T08:07:32.534931Z"
        },
        "trusted": true,
        "id": "c8wAPhNb-P9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pr_st_active_only = pr_st_active_only[pr_st_active_only['st_is_active']==1].reset_index(drop=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-09T08:07:32.677515Z",
          "iopub.execute_input": "2023-10-09T08:07:32.677872Z",
          "iopub.status.idle": "2023-10-09T08:07:32.684697Z",
          "shell.execute_reply.started": "2023-10-09T08:07:32.677836Z",
          "shell.execute_reply": "2023-10-09T08:07:32.683525Z"
        },
        "trusted": true,
        "id": "tLUkSoj0-P9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Объединение таблиц"
      ],
      "metadata": {
        "id": "t5oeJ_mF-P9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = sales_df_train.merge(pr_df, on='pr_sku_id', how='left')\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "QBL4aUgD-P9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_merged = merged_df.merge(pr_st_active_only, on='st_id', how='left')\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "eQJ7569g-P9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e3z504nx-P9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_merged.isna().sum()"
      ],
      "metadata": {
        "trusted": true,
        "id": "YjPH-696-P9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_merged.shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "GAtzxHfn-P9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "729 - это данные для неактивных магазинов. Можем удалять смело."
      ],
      "metadata": {
        "id": "kveLtnge-P9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_merged.dropna(inplace=True,ignore_index=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "7ljf4OUJ-P9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_merged.shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "N_d0cw1o-P9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_merged.isna().sum()"
      ],
      "metadata": {
        "trusted": true,
        "id": "vyHXSFs0-P9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Добаволяем признаки"
      ],
      "metadata": {
        "id": "gVW88-Qx-P9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "holiday_dict = {1:[i for i in range(1,10)],\n",
        "2:[23],\n",
        "3:[8],\n",
        "5:[1,9],\n",
        "6:[12],\n",
        "11:[4],\n",
        "12:[31]}"
      ],
      "metadata": {
        "trusted": true,
        "id": "btVFi67b-P9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_flag_holiday(row, holiday_dict):\n",
        "    '''\n",
        "    Функция размечает даты - праздник / не праздник\n",
        "    :param row: Таблица\n",
        "    :param holiday_dct: Словарь месяц:[число(1),...,число(i)]\n",
        "    '''\n",
        "\n",
        "    month = row['month']\n",
        "    day = row['date'].day\n",
        "    if month in holiday_dict and day in holiday_dict[month]:\n",
        "        return 1\n",
        "    return 0\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "DImc2W-u-P9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_merged['holiday'] = final_merged.apply(lambda row: set_flag_holiday(row, holiday_dict), axis=1)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "mm6Fozen-P9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_merged = final_merged.sort_values(by='date')"
      ],
      "metadata": {
        "trusted": true,
        "id": "XpMTRHdi-P9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ДФ ДЛЯ ТЕСТА ЛАГОВ"
      ],
      "metadata": {
        "id": "Os3rAriI-P9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_date = final_merged.copy()"
      ],
      "metadata": {
        "trusted": true,
        "id": "2xuIufCp-P9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_date['year'] = tmp_date['date'].dt.year\n",
        "tmp_date['day'] =tmp_date['date'].dt.day"
      ],
      "metadata": {
        "trusted": true,
        "id": "DbmiL6ML-P9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Предположим, что data_new - это ваш DataFrame\n",
        "tmp_date.rename(columns={'date': 'date_x'}, inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "LzzqtyzN-P9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем словарь для замены значений\n",
        "season_mapping = {'Зима': 0, 'Весна': 1, 'Лето': 2, 'Осень': 3}\n",
        "\n",
        "# Заменяем значения в столбце 'season' согласно словарю\n",
        "tmp_date['season'] = tmp_date['season'].replace(season_mapping)"
      ],
      "metadata": {
        "trusted": true,
        "id": "pP6l247m-P9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_group = tmp_date.groupby(['date_x', 'st_id', 'pr_sku_id']).agg({\n",
        "                                                                 'day':'mean' ,\n",
        "                                                                 'day_of_week':'mean',\n",
        "                                                                    'month':'mean',\n",
        "                                                                    'year':'mean',\n",
        "                                                                    'season':'mean',\n",
        "                                                                 'holiday':'mean',\n",
        "                                                                 'pr_sales_in_units':'sum'\n",
        "                                                                })"
      ],
      "metadata": {
        "trusted": true,
        "id": "253LVLlZ-P9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp=data_group.copy()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Hb_omhBO-P9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = tmp.reset_index()"
      ],
      "metadata": {
        "trusted": true,
        "id": "YSemNLVN-P9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_rec= tmp.drop_duplicates(subset=['date_x'])\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "6fVFB6g2-P9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_rec.reset_index(drop=False,inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "S_W6pXj5-P9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def after_holidays_n_days(row, n_before):\n",
        "    if row['holiday'] == 1:\n",
        "        return 1\n",
        "    for i in range(1, n_before + 1):\n",
        "        if row.name - i < 0:\n",
        "            break\n",
        "        if unique_rec.at[row.name - i, 'holiday'] == 1:\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "def before_holidays_n_days(row, n_after):\n",
        "    if row['holiday'] == 1:\n",
        "        return 1\n",
        "    for i in range(1, n_after + 1):\n",
        "        if row.name + i >= len(unique_rec):\n",
        "            break\n",
        "        if unique_rec.at[row.name + i, 'holiday'] == 1:\n",
        "            return 1\n",
        "    return 0\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "z2Y9KwIq-P9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_before = 14  # Количество дней до и после праздника\n",
        "unique_rec['before_holidays_n_days'] = unique_rec.apply(lambda row: before_holidays_n_days(row, n_before), axis=1)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "CCLXVmFZ-P9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_after= 7\n",
        "unique_rec['after_holidays_n_days'] = unique_rec.apply(lambda row: after_holidays_n_days(row, n_after), axis=1)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "x0XodPxg-P9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "before_after_day = unique_rec.loc[:,['date_x','before_holidays_n_days','after_holidays_n_days']]"
      ],
      "metadata": {
        "trusted": true,
        "id": "xBRlZQ-p-P9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = tmp.merge(before_after_day, on='date_x', how='left')\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "r4Gwxplr-P9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp= tmp.drop(columns=['day','day_of_week','month','season'],axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "X7BMxTUv-P9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp.head(2)"
      ],
      "metadata": {
        "trusted": true,
        "id": "vrYOOEXi-P9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Предположим, что data_new - это ваш DataFrame\n",
        "tmp.rename(columns={'date': 'date_x'}, inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "gOitWUAl-P9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "tmp = tmp.reset_index().set_index('date_x')\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "4EjtrByG-P9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp.drop('index',axis=1,inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZQ9hKG-c-P9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shop_list = tmp['st_id'].unique()\n",
        "product_list = tmp['pr_sku_id'].unique()"
      ],
      "metadata": {
        "trusted": true,
        "id": "MwUOmp8w-P9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wape_results = {}\n",
        "target = 'pr_sales_in_units'"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZRe1l-U8-P9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_new = pd.DataFrame()\n",
        "for shop in shop_list:\n",
        "    data_chunk = tmp.query('st_id == \\'{0}\\''.format(shop))\n",
        "    for product in product_list:\n",
        "        data_chunk_2 = data_chunk.query('pr_sku_id == \\'{0}\\''.format(product))\n",
        "        if data_chunk_2.shape[0] != 0:\n",
        "\n",
        "            #data_chunk_2 = data_chunk_2\n",
        "            data_chunk_2['month'] = data_chunk_2.index.month\n",
        "            data_chunk_2['year'] = data_chunk_2.index.year\n",
        "\n",
        "            idx = pd.date_range('{0}'.format(data_chunk_2.index.min()).replace('00:00:00', ''), '{0}'.format(data_chunk_2.index.max()).replace('00:00:00', ''))\n",
        "\n",
        "            s = pd.Series({})\n",
        "\n",
        "            s.index = pd.DatetimeIndex(s.index)\n",
        "            s = s.reindex(idx, fill_value=0)\n",
        "            s = pd.DataFrame(s, index=s.index)\n",
        "\n",
        "            data_tmp = s.merge(data_chunk_2, left_index=True, right_on='date_x', how='left')\n",
        "            data_tmp['st_id'] = data_tmp['st_id'].fillna(shop)\n",
        "            data_tmp['pr_sku_id'] = data_tmp['pr_sku_id'].fillna(product)\n",
        "            data_tmp['target_rolling_mean_3'] = data_tmp['pr_sales_in_units'].shift().rolling(3).mean()\n",
        "\n",
        "\n",
        "            data_new = pd.concat([data_new, data_tmp])\n",
        "\n",
        "\n",
        "data_new"
      ],
      "metadata": {
        "trusted": true,
        "id": "c_hyrV-P-P9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_new.loc[data_new['pr_sales_in_units'].isna(), 'pr_sales_in_units'] = data_new[data_new['pr_sales_in_units'].isna()]['target_rolling_mean_3']"
      ],
      "metadata": {
        "trusted": true,
        "id": "SjlAJRpU-P9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_new = data_new[~data_new['pr_sales_in_units'].isna()]"
      ],
      "metadata": {
        "trusted": true,
        "id": "0SNkuDSa-P9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_new.head(10)"
      ],
      "metadata": {
        "trusted": true,
        "id": "WuapYOAb-P9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_new.loc[data_new['pr_sales_in_units'].isna(), 'pr_sales_in_units'] = data_new[data_new['pr_sales_in_units'].isna()]['target_rolling_mean_3']"
      ],
      "metadata": {
        "trusted": true,
        "id": "vqajXkSj-P9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_new = data_new[~data_new['pr_sales_in_units'].isna()]"
      ],
      "metadata": {
        "trusted": true,
        "id": "42I6rymc-P9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_new = data_new.reset_index()\n",
        "data_new['date'] = data_new['index']"
      ],
      "metadata": {
        "trusted": true,
        "id": "VGUx4Xnm-P9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_new.loc[data_new['date'].isna(), 'date'] = data_new[data_new['date'].isna()]['date_x']"
      ],
      "metadata": {
        "trusted": true,
        "id": "GVZ4uspI-P9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_new = data_new.set_index('date')"
      ],
      "metadata": {
        "trusted": true,
        "id": "oy1KWWC5-P9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_new = data_new.drop([0, 'index', 'date_x', 'target_rolling_mean_3'], axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZE12FytJ-P9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_new.isna().sum()"
      ],
      "metadata": {
        "trusted": true,
        "id": "2_st6DMK-P9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_new= data_new.drop(columns=['month','year','holiday','before_holidays_n_days','after_holidays_n_days'],axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "fhNHlLE4-P9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_new = data_new[data_new['pr_sales_in_units']>0]"
      ],
      "metadata": {
        "trusted": true,
        "id": "lmMxgryj-P9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_new = data_new.reset_index()"
      ],
      "metadata": {
        "trusted": true,
        "id": "IbI3In3g-P9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_new['month'] = data_new.date.dt.month\n",
        "data_new['day_of_week'] = data_new.date.dt.dayofweek\n",
        "data_new['day'] = data_new.date.dt.day"
      ],
      "metadata": {
        "trusted": true,
        "id": "g8kCu1y5-P9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_new"
      ],
      "metadata": {
        "trusted": true,
        "id": "l1C37aCs-P9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_new= data_new.drop(['month',\"day_of_week\",\"day\"],axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "tSsEhArn-P9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_new"
      ],
      "metadata": {
        "trusted": true,
        "id": "BEXwM63b-P9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_features(data,cos_sin_columns = ['month','day_of_week','day'],    holiday_dict = {1:[i for i in range(1,10)],\n",
        "    2:[23],\n",
        "    3:[8],\n",
        "    5:[1,9],\n",
        "    6:[12],\n",
        "    11:[4],\n",
        "    12:[31]}):\n",
        "    data['date'] = pd.to_datetime(data['date'])\n",
        "    data['month'] = data['date'].dt.month\n",
        "\n",
        "    #  столбец 'season' с указанием времени года\n",
        "    seasons = {\n",
        "        1: 0,\n",
        "        2: 0,\n",
        "        3: 1,\n",
        "        4: 1,\n",
        "        5: 1,\n",
        "        6: 2,\n",
        "        7: 2,\n",
        "        8: 2,\n",
        "        9: 3,\n",
        "        10: 3,\n",
        "        11: 3,\n",
        "        12: 0\n",
        "    }\n",
        "    data['season'] = data['month'].map(seasons)\n",
        "    data['day'] = data['date'].dt.day\n",
        "    data['day_of_week'] =data['date'].dt.dayofweek\n",
        "    def set_flag_holiday(row, holiday_dict):\n",
        "        '''\n",
        "        Функция размечает даты - праздник / не праздник\n",
        "        :param row: Таблица\n",
        "        :param holiday_dct: Словарь месяц:[число(1),...,число(i)]\n",
        "        '''\n",
        "\n",
        "        month = row['month']\n",
        "        day = row['date'].day\n",
        "        weekday = row['day_of_week']\n",
        "        if (month in holiday_dict and day in holiday_dict[month]):\n",
        "            return 1\n",
        "        return 0\n",
        "\n",
        "\n",
        "    data['holiday'] = data.apply(lambda row: set_flag_holiday(row, holiday_dict), axis=1)\n",
        "    def after_holidays_n_days(row, n_before=14):\n",
        "        if row['holiday'] == 1:\n",
        "            return 1\n",
        "        for i in range(1, n_before + 1):\n",
        "            if row.name - i < 0:\n",
        "                break\n",
        "            if unique_rec.at[row.name - i, 'holiday'] == 1:\n",
        "                return 1\n",
        "        return 0\n",
        "\n",
        "    def before_holidays_n_days(row, n_after=7):\n",
        "        if row['holiday'] == 1:\n",
        "            return 1\n",
        "        for i in range(1, n_after + 1):\n",
        "            if row.name + i >= len(unique_rec):\n",
        "                break\n",
        "            if unique_rec.at[row.name + i, 'holiday'] == 1:\n",
        "                return 1\n",
        "        return 0\n",
        "\n",
        "    data = data.sort_values(by='date')\n",
        "    tmp=data.copy()\n",
        "    unique_rec= tmp.drop_duplicates(subset=['date'])\n",
        "    unique_rec.reset_index(drop=False,inplace=True)\n",
        "    unique_rec['before_holidays_n_days'] = unique_rec.apply(lambda row: before_holidays_n_days(row), axis=1)\n",
        "    unique_rec['after_holidays_n_days'] = unique_rec.apply(lambda row: after_holidays_n_days(row), axis=1)\n",
        "    before_after_day = unique_rec.loc[:,['date','before_holidays_n_days','after_holidays_n_days']]\n",
        "    data = data.merge(before_after_day, on='date', how='left')\n",
        "\n",
        "\n",
        "    def cos_sin_categorise(df,cos_column_name,sin_column_name,column_to_categorise):\n",
        "        \"\"\"\n",
        "        Применяет cos-sin тригонометрическую категоризацию\n",
        "\n",
        "        :param data: DataFrame содержащий данные\n",
        "        :param cos_column_name: Название будущей колонки с cos\n",
        "        :param sin_column_name: Название будущей колонки с sin\n",
        "        :param column_to_categorise: Назване колонки, которое хотим категоризовать\n",
        "        \"\"\"\n",
        "        df[cos_column_name] = np.cos((2*np.pi *df[column_to_categorise])/df[column_to_categorise].nunique())\n",
        "        df[sin_column_name] = np.sin((2*np.pi *df[column_to_categorise])/df[column_to_categorise].nunique())\n",
        "\n",
        "    for i in cos_sin_columns:\n",
        "        cos_sin_categorise(data,f'cos_{i}',f'sin_{i}',i)\n",
        "\n",
        "    def set_flag_holiday_weekend(row, holiday_dict):\n",
        "        '''\n",
        "        Функция размечает даты - праздник / не праздник\n",
        "        :param row: Таблица\n",
        "        :param holiday_dct: Словарь месяц:[число(1),...,число(i)]\n",
        "        '''\n",
        "\n",
        "        month = row['month']\n",
        "        day = row['date'].day\n",
        "        weekday = row['day_of_week']\n",
        "        if (month in holiday_dict and day in holiday_dict[month])or (weekday in [5,6]):\n",
        "            return 1\n",
        "        return 0\n",
        "    data['holiday'] = data.apply(lambda row: set_flag_holiday_weekend(row, holiday_dict), axis=1)\n",
        "    data['date'] = pd.to_datetime(data['date'])\n",
        "    sales_df_train['date'] = pd.to_datetime(sales_df_train['date'])\n",
        "    data.drop(['day','month','day_of_week'],axis=1,inplace=True)\n",
        "    data = data.merge(pr_df, on='pr_sku_id', how='left')\n",
        "\n",
        "    data = data.merge(pr_st_active_only, on='st_id', how='left')\n",
        "    data = data.merge(sales_df_train.loc[:,['date','pr_sku_id','pr_sales_type_id']],on=['date','pr_sku_id'],how='left')\n",
        "    features_columns_list = ['st_id', 'pr_sku_id', 'date', 'holiday', 'season', 'cos_month', 'sin_month',\n",
        "       'cos_day_of_week', 'sin_day_of_week', 'cos_day', 'sin_day',\n",
        "       'before_holidays_n_days', 'after_holidays_n_days','pr_sales_type_id',\n",
        "       'pr_uom_id']\n",
        "\n",
        "    data = data.reindex(columns=features_columns_list)\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-09T08:07:04.897544Z",
          "iopub.execute_input": "2023-10-09T08:07:04.897909Z",
          "iopub.status.idle": "2023-10-09T08:07:04.919708Z",
          "shell.execute_reply.started": "2023-10-09T08:07:04.897879Z",
          "shell.execute_reply": "2023-10-09T08:07:04.918182Z"
        },
        "trusted": true,
        "id": "61doUbIO-P9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_new = make_features(data_new)"
      ],
      "metadata": {
        "trusted": true,
        "id": "dY0MADHN-P9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "for season in tqdm(season_dataframes.keys(), desc=\"Processing Season\"):\n",
        "    test_end_date = season_dataframes[season]['date'].max()\n",
        "    # Вычисляем начальную дату, отсчитывая от конца\n",
        "    test_start_date = test_end_date - timedelta(days=days_to_keep_in_test - 1)\n",
        "    # Фильтруем данные для тестовой выборки\n",
        "    data_new_test = season_dataframes[season][(season_dataframes[season]['date'] >= test_start_date) & (season_dataframes[season]['date'] <= test_end_date)]\n",
        "    # Фильтруем данные для тренировочной выборки (оставляем все, кроме тестовой части)\n",
        "    data_new_train = season_dataframes[season][season_dataframes[season]['date'] < test_start_date]\n",
        "    lag_df_train = pd.DataFrame()\n",
        "    # Перебираем уникальные пары магазин-товар\n",
        "    for store in tqdm(data_new_train.st_id.unique(), desc=\"Processing Stores Train\"):\n",
        "        for product in data_new_train.pr_sku_id.unique():\n",
        "            subset = data_new_train[(data_new_train['st_id'] == store) & (data_new_train['pr_sku_id'] == product)].copy()\n",
        "            # Фильтруем DataFrame для текущей пары магазин-товар\n",
        "            subset['lag_1_sales'] = subset['pr_sales_in_units'].shift(periods=1)\n",
        "            subset['lag_2_sales'] = subset['pr_sales_in_units'].shift(periods=2)\n",
        "            subset['lag_7_sales'] = subset['pr_sales_in_units'].shift(periods=7)\n",
        "            subset['lag_14_sales'] = subset['pr_sales_in_units'].shift(periods=14)\n",
        "            # Вычисляем скользящее среднее за 7 дней\n",
        "            subset['rolling_mean_2'] = subset['pr_sales_in_units'].shift().rolling(window=2).mean()\n",
        "            subset['rolling_mean_7'] = subset['pr_sales_in_units'].shift().rolling(window=7).mean()\n",
        "            subset['rolling_mean_14'] = subset['pr_sales_in_units'].shift().rolling(window=14).mean()\n",
        "\n",
        "\n",
        "            # Добавляем результаты в общий DataFrame\n",
        "            lag_df_train = pd.concat([lag_df_train, subset])\n",
        "            lag_df_train = lag_df_train.fillna(value=0)\n",
        "    # Создаем новый DataFrame для хранения лагов\n",
        "    lag_df_test = pd.DataFrame()\n",
        "\n",
        "    # Перебираем уникальные пары магазин-товар\n",
        "# Перебираем уникальные пары магазин-товар\n",
        "    for store in tqdm(data_new_test.st_id.unique(), desc=\"Processing Stores Test\"):\n",
        "        for product in data_new_test.pr_sku_id.unique():\n",
        "            # Фильтруем DataFrame для текущей пары магазин-товар\n",
        "            subset = data_new_test[(data_new_test['st_id'] == store) & (data_new_test['pr_sku_id'] == product)].copy()\n",
        "            # Создаем лаги\n",
        "            subset['lag_1_sales'] = subset['pr_sales_in_units'].shift(periods=1)\n",
        "            subset['lag_2_sales'] = subset['pr_sales_in_units'].shift(periods=2)\n",
        "            subset['lag_7_sales'] = subset['pr_sales_in_units'].shift(periods=7)\n",
        "            subset['lag_14_sales'] = subset['pr_sales_in_units'].shift(periods=14)\n",
        "            # Вычисляем скользящее среднее за 7 дней\n",
        "            subset['rolling_mean_2'] = subset['pr_sales_in_units'].shift().rolling(window=2, min_periods=2).mean()\n",
        "            subset['rolling_mean_7'] = subset['pr_sales_in_units'].shift().rolling(window=7, min_periods=7).mean()\n",
        "            subset['rolling_mean_14'] = subset['pr_sales_in_units'].shift().rolling(window=14, min_periods=14).mean()\n",
        "            # Заполняем пропущенные значения скользящим средним\n",
        "            # Добавляем результаты в общий DataFrame\n",
        "            lag_df_test = pd.concat([lag_df_test, subset])\n",
        "            lag_df_test = lag_df_test.fillna(value=0)\n",
        "    lag_df_train.drop(['date'],axis=1,inplace=True)\n",
        "    lag_df_test.drop(['date'],axis=1,inplace=True)\n",
        "    features_lag_train = lag_df_train.drop('pr_sales_in_units',axis=1)\n",
        "    target_lag_train = lag_df_train.pr_sales_in_units\n",
        "    features_lag_test = lag_df_test.drop('pr_sales_in_units',axis=1)\n",
        "    target_lag_test = lag_df_test.pr_sales_in_units\n"
      ],
      "metadata": {
        "id": "7_zHj-xV-P9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CNp5_pAo-P9a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}